{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf4027f7-e8c6-4047-aacf-b7d0b1d746d1",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8d53b-fcc5-4221-9e41-916e6f465935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly import graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "from IPython.display import HTML\n",
    "import cufflinks\n",
    "import numba as nb\n",
    "from scipy.optimize import least_squares, curve_fit\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.svm import SVC # Support Vector Classifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import mlflow\n",
    "import os\n",
    "import mlflow.keras\n",
    "import mlflow.sklearn\n",
    "from gewapro.cache import cache\n",
    "from gewapro.preprocessing import get_waveforms, train_test_split_cond, smoothen_waveforms, get_and_smoothen_waveforms, select_from_source\n",
    "from gewapro.functions import (quadratic_arr,\n",
    "                               fit_parabolas,\n",
    "                               df_with_fits,\n",
    "                               _fit_final_slope,\n",
    "                               combine_and, combine_or,\n",
    "                               calc_ab)\n",
    "from gewapro.plotting.base import _fwhm_energy_df\n",
    "from gewapro.util import name_to_vals, pandas_string_rep, add_notes, combine_cols_with_errors\n",
    "from gewapro.plotting import (histogram,\n",
    "                              corr_fig,\n",
    "                              mlp_reg_fig,\n",
    "                              plot_transform,\n",
    "                              energy_histogram,\n",
    "                              box_plot,\n",
    "                              plot_predictions,\n",
    "                              energy_line_plot,\n",
    "                              add_energy_histogram,\n",
    "                              combine_line_plots,\n",
    "                              combined_channel_line_plot,\n",
    "                              change_combined_line_fig)\n",
    "from gewapro import plotting\n",
    "from gewapro.models import regressor_model, train_model, get_model_version_map, ModelInfo, fitted_PCA\n",
    "import gewapro.models\n",
    "from gewapro.experiment_flow import run_experiment\n",
    "import mlflow.pyfunc\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "\n",
    "cufflinks.go_offline()\n",
    "# gewapro.models.update_validity()\n",
    "\n",
    "# First run 'mlflow ui' in a terminal, otherwise this will not work!!!\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abde9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all data loaded\n",
    "data_g1274_name = \"20231110-Na22-d0-12-tz6-ML200-g1274.dat\"\n",
    "data_g511_name = \"20231110-Na22-d0-12-tz6-ML200-g511.dat\"\n",
    "data_g1274_unfiltered_name = \"20231110-Na22-d0-12-tz6-ML200_nofir_noMa_D40-g1274.dat\"\n",
    "data_g511_unfiltered_name = \"20231110-Na22-d0-12-tz6-ML200_nofir_noMa_D40-g511.dat\"\n",
    "data_g1274_partfltr_name_all = \"20231110-Na22-d0-12-tz6-ML200_noMa_D10_soft_sc_g1274_all.parquet\"\n",
    "data_g511_partfltr_name_all = \"20231110-Na22-d0-12-tz6-ML200_noMa_D10_soft_sc_g511_all.parquet\"\n",
    "data_g1274_partfltr_name_all2 = \"20231117-Na22-d0-12-tz6-ML200_noMa_D10_soft_sc_g1274_all.parquet\"\n",
    "data_g511_partfltr_name_all2 = \"20231117-Na22-d0-12-tz6-ML200_noMa_D10_soft_sc_g511_all.parquet\"\n",
    "name_g1274_d = lambda i: f\"20231110-Na22-d{i}-tz6-ML200_noMa_D10_soft_sc_g1274.dat\"\n",
    "name_g511_d = lambda i: f\"20231110-Na22-d{i}-tz6-ML200_noMa_D10_soft_sc_g511.dat\"\n",
    "name2_g1274_d = lambda i: f\"20231117-Na22-d{i}-12-tz6-ML200_noMa_D10_soft_sc_g1274_all.parquet\"\n",
    "name2_g511_d = lambda i: f\"20231117-Na22-d{i}-12-tz6-ML200_noMa_D10_soft_sc_g511_all.parquet\"\n",
    "data_dict = {\n",
    "             data_g1274_name:              (datag1274 := pd.read_csv(\"data/\"+data_g1274_name)),\n",
    "             data_g511_name:               (datag511 := pd.read_csv(\"data/\"+data_g511_name)),\n",
    "             data_g1274_unfiltered_name:   (datag1274unfiltered := pd.read_csv(\"data/\"+data_g1274_unfiltered_name)),\n",
    "             data_g511_unfiltered_name:    (datag511unfiltered := pd.read_csv(\"data/\"+data_g511_unfiltered_name)),\n",
    "             data_g1274_partfltr_name_all: (datag1274partfltr_all := pd.read_parquet(\"data/\"+data_g1274_partfltr_name_all)),\n",
    "             data_g511_partfltr_name_all:  (datag511partfltr_all := pd.read_parquet(\"data/\"+data_g511_partfltr_name_all)),\n",
    "             data_g1274_partfltr_name_all2:(datag1274partfltr_all2 := pd.read_parquet(\"data/\"+data_g1274_partfltr_name_all2)),\n",
    "             data_g511_partfltr_name_all2: (datag511partfltr_all2 := pd.read_parquet(\"data/\"+data_g511_partfltr_name_all2)),\n",
    "            } | {\n",
    "                    name_g1274_d(i): select_from_source(datag1274partfltr_all, select_channels=[i]) for i in range(0,13)\n",
    "            } | {\n",
    "                    name_g511_d(i): select_from_source(datag511partfltr_all, select_channels=[i]) for i in range(0,13)\n",
    "            } | {\n",
    "                    name2_g1274_d(i): select_from_source(datag1274partfltr_all2, select_channels=[i]) for i in range(0,13)\n",
    "            } | {\n",
    "                    name2_g511_d(i): select_from_source(datag511partfltr_all2, select_channels=[i]) for i in range(0,13)\n",
    "            }\n",
    "x_to_t = lambda x: 160-(x*4)\n",
    "t_to_x = lambda t: (160-t)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd49c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Usable waveforms:\",len(datag511partfltr_all2[(datag511partfltr_all2[\"Ch\"] != 4) & (datag511partfltr_all2[\"Ch\"] != 6)]))\n",
    "print(datag511partfltr_all2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 100 waveforms\n",
    "dfplot = get_waveforms(select_channels=0,source_data=datag1274partfltr_all)\n",
    "print(\"Total waveform count:\",len(dfplot.columns))\n",
    "dfplot85_95: pd.DataFrame = dfplot.loc[:,(dfplot.loc[199] > 0.85) & (dfplot.loc[199] < 0.95)]\n",
    "dfplot85: pd.DataFrame = dfplot.loc[:,dfplot.loc[199] < 0.85]\n",
    "# dfplot.iloc[:,:100].iplot(title=\"First 100 waveforms\")\n",
    "dfplot85_95.iloc[:,:100].set_index(dfplot85.index*4).iplot(title=\"First 100 waveforms with last value between 0.85 and 0.95\",theme=\"white\")\n",
    "fig = dfplot85_95.iloc[:,:100].set_index(dfplot85.index*4).iplot(asFigure=True,theme=\"white\").update_layout(height=400,width=700,margin=dict(l=20, r=20, t=20, b=20),showlegend=False,xaxis_title=\"time [ns]\",yaxis_title=\"Normalised signal\")\n",
    "# fig.show()\n",
    "# fig.write_image(\"0_Waveforms_8595_first100_partfltr.pdf\")\n",
    "dfplot85.iloc[:,:100].iplot(title=\"First 100 waveforms with last value below 0.85\")\n",
    "fig = dfplot85.iloc[:,:100].set_index(dfplot85.index*4).iplot(asFigure=True,theme=\"white\").update_layout(height=400,width=700,margin=dict(l=20, r=20, t=20, b=20),showlegend=False,xaxis_title=\"time [ns]\",yaxis_title=\"Normalised signal\")\n",
    "# fig.show()\n",
    "# fig.write_image(\"1_Waveforms_lt85_first100_partfltr.pdf\")\n",
    "print(f\"Final point <0.85 rate: {len(dfplot85.columns)/len(dfplot.columns):.2%} ({len(dfplot85.columns)} waveforms), 0.85-0.95 rate: {len(dfplot85_95.columns)/len(dfplot.columns):.2%} ({len(dfplot85_95.columns)} waveforms)\")\n",
    "# data_dict[\"raw\"][\"normalized\"][\"FIR\"][\"gBOTH\"][\"range_cut\"].iloc[:,:50].iplot(title=\"First 50 partially filtered normalized waveforms E(4000-5000)(11050-11250)\")\n",
    "get_waveforms(source_data=data_dict[name_g511_d(0)], select_energies=(4000,5000)).iloc[:,:100].iplot(title=\"First 100 partially filtered normalized waveforms\")\n",
    "\n",
    "dfw = get_waveforms(source_data=data_dict[name_g511_d(0)], select_energies=(4000,5000)).iloc[:,:100]\n",
    "fig = dfw.rename(columns={c:c[:c.find(\"]\")+1] for c in dfw.columns}).set_index(dfplot85.index*4).iplot(asFigure=True,theme=\"white\").update_layout(height=400,width=700,margin=dict(l=20, r=20, t=20, b=20),showlegend=False,xaxis_title=\"time [ns]\",yaxis_title=\"Normalised signal\")\n",
    "# fig.show()\n",
    "# fig.write_image(\"2_Waveforms_fine_first100_partfltr.pdf\")\n",
    "dfplot85.iloc[:,100:].iplot(title=\"First 100 partially filtered normalized waveforms with final_val<0.85 removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10dffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_diff = datag511partfltr_all[\"dT\"] - datag511partfltr_all[\"Tfit\"]\n",
    "s_diff.name = \"dT - Tfit\"\n",
    "# display(pd.concat([datag511partfltr_all,s_diff],axis=1).loc[datag511partfltr_all[\"Ch\"] == 1, :])\n",
    "histogram(pd.concat([datag511partfltr_all,s_diff],axis=1).loc[datag511partfltr_all[\"Ch\"] == 3, [s_diff.name,\"Tfit\",\"dT\",\"T0\"]],bins=[-30,30,1])\n",
    "\n",
    "print(ModelInfo.from_database(model_name=\"MLPRegressorModel\",model_version=5))\n",
    "print(ModelInfo.from_database(model_name=\"MLPRegressorModel\",model_version=2992))\n",
    "# print(ModelInfo.from_database(\"MLPRegressorModel\",model_version=2993)) # 2993-2996 do not exist\n",
    "print(energy_line_plot.cache_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb0665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCAcomp.  BEST / WORST (g511)     BEST / WORST (g1274)\n",
    "# 20:       2353 / 2355             2373 / 2370\n",
    "# 21:       2360 / 2357             2374 / 2379\n",
    "# 22:       2361 / 2365             2383 / 2384\n",
    "# df_results = pd.DataFrame({\"model\":[2353, 2360, 2361, 2373, 2374, 2383, 2355, 2357, 2365, 2370, 2379, 2384],\n",
    "#                            \"PCA components\":[20, 21, 22]*4,\"_g511\": [np.nan]*12,\"FWHM_g1274\": [np.nan]*12,\n",
    "#                            \"FWHM_g511 (450-600)\": [np.nan]*12,\"FWHM_g1274 (450-600)\": [np.nan]*12,\n",
    "#                            \"trained_on\":([\"g511\"]*3+[\"g1274\"]*3)*2,\n",
    "#                            }).set_index(\"model\")#rename_axis(\"limbs\", axis=\"columns\")\n",
    "# for model in df_results.index:\n",
    "#     model_pred_fig_511 = plot_predictions(data_g511_name, (11050,11250), model, data_dict, \"MLPRegressorModel\", False)\n",
    "#     model_pred_fig_1274 = plot_predictions(data_g1274_name, (4000,5000), model, data_dict, \"MLPRegressorModel\", False)\n",
    "#     model_pred_fig_511_515 = plot_predictions(data_g511_name, (450,600), model, data_dict, \"MLPRegressorModel\", False)\n",
    "#     model_pred_fig_1274_515 = plot_predictions(data_g1274_name, (450,600), model, data_dict, \"MLPRegressorModel\", False)\n",
    "#     df_results.loc[model, \"FWHM_g511\"] = model_pred_fig_511._params[\"dT_act - dT_pred Gaussian\"][\"sigma\"]*2*np.sqrt(2*np.log(2))\n",
    "#     df_results.loc[model, \"FWHM_g1274\"] = model_pred_fig_1274._params[\"dT_act - dT_pred Gaussian\"][\"sigma\"]*2*np.sqrt(2*np.log(2))\n",
    "#     df_results.loc[model, \"FWHM_g511 (450-600)\"] = model_pred_fig_511_515._params[\"dT_act - dT_pred Gaussian\"][\"sigma\"]*2*np.sqrt(2*np.log(2))\n",
    "#     df_results.loc[model, \"FWHM_g1274 (450-600)\"] = model_pred_fig_1274_515._params[\"dT_act - dT_pred Gaussian\"][\"sigma\"]*2*np.sqrt(2*np.log(2))\n",
    "# display(df_results)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def lineariser(df: pd.DataFrame, lin_term: float, bias: float = 0):\n",
    "    return (df.max().values * lin_term) + bias\n",
    "\n",
    "def part_lin(lin_term: float, bias: float = 0):\n",
    "    return partial(lineariser, lin_term=lin_term, bias=bias) #custom_func=part_lin(0.01)\n",
    "\n",
    "#  511 * x - 17.8370 + y = 0  -   (0.034906 * 511 = )\n",
    "# 1274 * x +  8.6423 + y = 0  +     ()\n",
    "# =============================\n",
    "#  763 * x + 26.4793     = 0    -> x,y = -0.034704194,35.57084313\n",
    "import mlflow.pyfunc\n",
    "regressor = mlflow.pyfunc.load_model(model_uri=f\"models:/MLPRegressorModel/2398\")\n",
    "# print(isinstance(regressor, mlflow.pyfunc.PyFuncModel), str(regressor.loader_module) == \"mlflow.sklearn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfe491",
   "metadata": {},
   "source": [
    "### Run experiments..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single experiment\n",
    "model_type = \"sklearn\" # or \"sklearn\" or \"xgboost\"\n",
    "                                            # data511 or datag511partfltr or datag511unfiltered\n",
    "# data_and_name = datag511partfltr,data_g511_partfltr_name # data_g511_name or data_g511_partfltr_name\n",
    "data_and_name = select_from_source(datag511partfltr_all,select_channels=[0,2,5,8,9,10]),name_g511_d([0,2,5,8,9,10]) # test: 1,3,7,11\n",
    "# data_temp_dict = {data_and_name[0]:data_and_name[1]}\n",
    "\n",
    "if model_type == \"xgboost\":\n",
    "    ...\n",
    "    # result_single_exp = run_experiment(\n",
    "    #     data=data_and_name[0],  \n",
    "    #     data_name=data_and_name[1],\n",
    "    #     select_channels=[0],\n",
    "    #     select_energies=(11050,11250),\n",
    "    #     pca_components=None,\n",
    "    #     model_type=\"xgboost\",\n",
    "    #     max_depth=50,\n",
    "    #     n_estimators=3,\n",
    "    #     max_leaves= 0,\n",
    "    #     test_size=0.2,\n",
    "    #     uniform_test_set=[5000,6000,7000,8000,9000,10000,11000,12000]#,8000,9000,10000,11000]\n",
    "    # )\n",
    "else:\n",
    "    result_single_exp = run_experiment(\n",
    "        data=data_and_name[0],\n",
    "        data_name=data_and_name[1],\n",
    "        select_channels=[],\n",
    "        select_energies=(5000,15000),\n",
    "        pca_components=None,\n",
    "        model_type=\"sklearn\",\n",
    "        hidden_layers=[23],\n",
    "        test_size=0.3,\n",
    "        uniform_test_set=[5000,6000,7000,8000,9000,10000,11000,12000,13000,15000], #,8000,9000,10000,11000]\n",
    "        dT_correcting=True\n",
    "    )#._params\n",
    "result_single_exp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de984a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params= {\"model_type\": \"SKlearn\",\n",
    "                 \"select_channels\": [0,1,3,5,7,9,10], # Test: 2, 8, 11\n",
    "                 \"max_iterations\": 2_000,\n",
    "                 \"remove_nan_waveforms\":True,\n",
    "                #  \"select_energies\":(9000,13000), # DEFAULT for th06-th60: (11050,11250)\n",
    "                 \"include_energy\": False,\n",
    "                 \"activation\": 'relu',\n",
    "                 \"pca_method\": PCA,\n",
    "                 \"uniform_test_set\": [5000,6000,7000,8000,9000,10000,11000],\n",
    "                 \"test_size\":0.3,\n",
    "                 \"which\": \"Tfit\"}\n",
    "source_dat = select_from_source(datag511partfltr_all2,select_channels=[0,1,3,5,7,9,10])\n",
    "data_run = {name2_g511_d([0,1,3,5,7,9,10])+\"+.95\": source_dat.loc[source_dat[\"s199\"] >= .95]}\n",
    "\n",
    "# pca_components_list = [None] #[100,None] #[16,18,20,21,22,23,64]\n",
    "# hidden_layers_list = [[100]] #[5,10,20,50]\n",
    "# Final EXP NN: [[100,[23]],[128,[64]],[128,[128]],[None,[23]]]\n",
    "pca_hidden_layers_list = [[None,[23]]] #[[4,[4]],[8,[8]],[12,[12]],[16,[16]],[20,[20]],[20,[16]],[24,[24]],[24,[16]],[28,[28]],[28,[16]],[32,[32]],[32,[16]],[48,[48]],[48,[16]],[64,[64]],[64,[16]],[128,[128]],[128,[16]],[None,[24]],[None,[16]]]\n",
    "select_energies = [(5000,50000)] #[(9000,50000),(8000,50000)] #[(10000,50000),(5000,13000),()]\n",
    "which = [\"Tfit\"]\n",
    "exp_list = [[obj for obj in tup] for tup in itertools.product([k for k in data_run.keys()],pca_hidden_layers_list,select_energies,which)]\n",
    "print(exp_list)\n",
    "iterations = [5]*len(exp_list)\n",
    "print(len(exp_list),\"experiments,\",sum(iterations), f\"iterations (={sum(iterations)/len(exp_list)}*{len(pca_hidden_layers_list)}*{len(which)})\")\n",
    "results = {}\n",
    "# break\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\") # 5000: local, 30000: external\n",
    "iteration = 0\n",
    "for exp,iters in zip(exp_list,iterations):\n",
    "    params = default_params\n",
    "    params |= {\"pca_components\": exp[1][0], \"hidden_layers\": exp[1][1], \"select_energies\": exp[2], \"which\":exp[3]}\n",
    "    result = {str(i):None for i in range(iters)}\n",
    "    # if [exp[1]] == exp[2] == 22:\n",
    "    #     print(f\"Got layers {[exp[1]]} equal to {exp[2]}, skipping experiment\")\n",
    "    #     continue\n",
    "    for i in range(iters):\n",
    "        iteration += 1\n",
    "        print(f\"[MLFlow run] Starting iteration {i+1}/{iters} ({iteration}/{sum(iterations)}) with params {params}...\")\n",
    "        if \"raw\" in exp[0]:\n",
    "            result[str(i)] = run_experiment(data_run[exp[0]], exp[0], **params)._params\n",
    "        else:\n",
    "            result[str(i)] = run_experiment(data_run[exp[0]], exp[0], **params)._params\n",
    "    results[str(exp)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_waveforms(source_data=data, select_energies=range_E, include_energy=False)\n",
    "# Best results:         abs                                 avg\n",
    "# E5000-6000    13.358  8000-50000, 100-[23] @ 10.485       5000-13000, 100-[16] @ 10.71\n",
    "# E6000-7000    11.841  9000-13000, 23-[100] @  9.227       9000-13000, 23-[100] @  9.61\n",
    "# E7000-8000    10.374  9000-50000, 23-[23]  @  8.682       9000-50000, 23-[100] @  8.82\n",
    "# E8000-9000    10.292  5000-13000, ALL-[100] @ 8.371       5000-13000, ALL-[100] @ 8.49\n",
    "# E9000-10000    9.439  9000-13000, 23-[100] @  7.689       5000-13000, 100-[16] @  7.92\n",
    "# E10000-11000  11.282  5000-13000, ALL-[100] @ 7.034       5000-13000, ALL-[100] @ 7.12\n",
    "# E11000-12000   7.064  5000-13000, 100-[16] @  6.004       5000-13000, 100-[16] @  6.28\n",
    "\n",
    "# Eleastsquares 2949:  8000-50000 100-[23]  @ 5.599, 2897:  5000-13000 ALL-[100] @ 5.608, 2851:  5000-13000 100-[16] @ 5.605\n",
    "#                739:  8000-13000 16-4*40   @ 3.444,  748:  8000-13000 16-4*50   @ 3.475,  743:  8000-50000 16-4*50  @ 3.512\n",
    "# Elinear       2897:  5000-13000 ALL-[100] @ 5.651, 2949:  8000-50000 100-[23]  @ 5.654, 2851:  5000-13000 100-[16] @ 5.662\n",
    "#                748:  8000-13000 16-4*50   @ 4.367,  743:  8000-50000 16-4*50   @ 4.410,  739:  8000-13000 16-4*40  @ 4.447\n",
    "# Try 2995       2949 & 2897\n",
    "plotting.settings(show_dt=True,show_pred=True)\n",
    "ignore_values = {\"Energy range used\": \"() eV\"}\n",
    "ignore_values1 = {\"tree depth\": None}\n",
    "energy = 5000\n",
    "y = f\"FWHM E{energy}-{energy+1000}\"\n",
    "\n",
    "def square_FWHM_metric(df: pd.DataFrame) -> pd.Series:\n",
    "    ranges = {\"5000-6000\":13.3579,\"6000-7000\":11.841,\"7000-8000\":10.3735,\"8000-9000\":10.2916,\"9000-10000\":9.4387,\"10000-11000\":11.2823,\"11000-12000\":7.0638}\n",
    "    return sum([(df[f\"metrics.Uniform test FWHM E{e_range}\"]/e_val)**2 for e_range,e_val in ranges.items()])\n",
    "\n",
    "def linear_FWHM_metric(df: pd.DataFrame) -> pd.Series:\n",
    "    ranges = {\"5000-6000\":13.3579,\"6000-7000\":11.841,\"7000-8000\":10.3735,\"8000-9000\":10.2916,\"9000-10000\":9.4387,\"10000-11000\":11.2823,\"11000-12000\":7.0638}\n",
    "    return sum([df[f\"metrics.Uniform test FWHM E{e_range}\"]/e_val for e_range,e_val in ranges.items()])\n",
    "linear_FWHM_metric.FWHM = square_FWHM_metric.FWHM = 7\n",
    "\n",
    "y = square_FWHM_metric\n",
    "\n",
    "# df_version_mapper = get_model_version_map([102816600889877627])\n",
    "# display(df_version_mapper)\n",
    "# display(get_model_version_map([918309536924112984]))\n",
    "box_plot([918309536924112984], x=\"Energy range used\", y=y, color=\"PCA components\", ignore_vals=ignore_values, facet_row=\"Hidden layers\", height=700, hover_name=\"model_version\").show()\n",
    "# box_plot([102816600889877627], x=\"estimators\", y=y, color=\"PCA components\", ignore_vals=ignore_values1, facet_row=\"tree depth\", facet_col=\"Energy range used\", hover_name=\"model_version\", height=800).show()\n",
    "# box_plot([941575026271596123], x=\"PCA components\", y=y, color=\"Hidden layers\", height=700, hover_name=\"model_version\").show()\n",
    "box_plot([824072748444866548], x=\"PCA components\", y=y, color=\"Energy range used\", facet_col=\"Tref\", height=700, hover_name=\"model_version\").show()\n",
    "box_plot([824072748444866548], x=\"PCA components\", y=\"FWHM Test\", color=\"Energy range used\", facet_col=\"Tref\", height=700, hover_name=\"model_version\").show()\n",
    "waveforms5000_13000 = get_waveforms(source_data=data[\"partfilter_g511_all2_E5000-13000\"])\n",
    "waveforms5000_50000 = get_waveforms(source_data=data[\"partfilter_g511_all2_E5000-50000\"])\n",
    "energy_line_plot(name_g511_d(0), 2000, 10000, 250, 3158, data, PCA_fit=fitted_PCA(3158, waveforms5000_13000),hist_limit=100,y_sd=\"FWHM GoF\",verbose=0).show()\n",
    "energy_line_plot(name_g511_d(0), 2000, 10000, 250, 3139, data, PCA_fit=fitted_PCA(3139, waveforms5000_13000),hist_limit=100,y_sd=\"FWHM GoF\",verbose=0).show()\n",
    "energy_line_plot(name_g511_d(0), 2000, 10000, 250, 3077, data, PCA_fit=fitted_PCA(3077, waveforms5000_13000),hist_limit=100,y_sd=\"FWHM GoF\",verbose=0).show()\n",
    "energy_line_plot(name_g511_d(0), 2000, 10000, 250, 3066, data, PCA_fit=fitted_PCA(3066, waveforms5000_50000),hist_limit=100,y_sd=\"FWHM GoF\",verbose=0,which=\"Tfit\").show()\n",
    "energy_line_plot(name_g511_d(1), 2000, 10000, 250, 3158, data, PCA_fit=fitted_PCA(3158, waveforms5000_13000),hist_limit=100,y_sd=\"FWHM GoF\",verbose=0).show()\n",
    "energy_line_plot(name_g511_d(1), 2000, 10000, 250, 3139, data, PCA_fit=fitted_PCA(3139, waveforms5000_13000),hist_limit=100,y_sd=\"FWHM GoF\",verbose=0).show()\n",
    "energy_line_plot(name_g511_d(1), 2000, 10000, 250, 3077, data, PCA_fit=fitted_PCA(3077, waveforms5000_13000),hist_limit=100,y_sd=\"FWHM GoF\",verbose=0).show()\n",
    "energy_line_plot(name_g511_d(1), 2000, 10000, 250, 3066, data, PCA_fit=fitted_PCA(3066, waveforms5000_50000),hist_limit=100,y_sd=\"FWHM GoF\",verbose=0,which=\"Tfit\").show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 3032, data, \"MLPRegressorModel\", PCA_fit=fitted_PCA(3032, waveforms)).show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 3028, data, \"MLPRegressorModel\", PCA_fit=fitted_PCA(3028, waveforms)).show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 3000, data, \"MLPRegressorModel\", PCA_fit=fitted_PCA(3000, waveforms)).show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 3033, data, \"MLPRegressorModel\").show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 2949, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E8000-50000\").show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 2897, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E5000-13000\").show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 2851, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E5000-13000\").show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 739, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-13000\").show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 748, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-13000\").show()\n",
    "# plot_predictions(data_g511_partfltr_name, (), 743, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-50000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel,model_v,fitted_pca,which in [(0,3058,fitted_PCA(3058, waveforms5000_13000),\"T0\"),\n",
    "                                         (1,3058,fitted_PCA(3058, waveforms5000_13000),\"T0\"),\n",
    "                                         (0,3066,fitted_PCA(3066, waveforms5000_50000),\"Tfit\"),\n",
    "                                         (1,3066,fitted_PCA(3066, waveforms5000_50000),\"Tfit\")]:  # Fitting takes about 1.5 min, plotting is nearly instant\n",
    "    plot_predictions(name_g511_d(channel),(2375,2625),model_v,data,\"MLPRegressorModel\",channel,PCA_fit=fitted_pca,which=which,title=f\"Predictions of NN v{model_v} on Ch{channel}, @E 2500 (arb. units, binwidth 250)\").show()\n",
    "    plot_predictions(name_g511_d(channel),(4875,5125),model_v,data,\"MLPRegressorModel\",channel,PCA_fit=fitted_pca,which=which,title=f\"Predictions of NN v{model_v} on Ch{channel}, @E 5000 (arb. units, binwidth 250)\").show()\n",
    "    plot_predictions(name_g511_d(channel),(8875,9125),model_v,data,\"MLPRegressorModel\",channel,PCA_fit=fitted_pca,which=which,title=f\"Predictions of NN v{model_v} on Ch{channel}, @E 9000 (arb. units, binwidth 250)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on other detectors\n",
    "detector = 1\n",
    "data |= {name_g511_d(detector): data_dict[name_g511_d(detector)]}\n",
    "plot_predictions(name_g511_d(detector), (), 2949, data, \"MLPRegressorModel\", PCA_fit=\"partfilter_g511_E8000-50000\").show()\n",
    "plot_predictions(name_g511_d(detector), (), 2897, data, \"MLPRegressorModel\", PCA_fit=\"partfilter_g511_E5000-13000\").show()\n",
    "plot_predictions(name_g511_d(detector), (), 2851, data, \"MLPRegressorModel\", PCA_fit=\"partfilter_g511_E5000-13000\").show()\n",
    "plot_predictions(name_g511_d(detector), (), 739, data, \"XGBoostedTree\", PCA_fit=\"partfilter_g511_E8000-13000\").show()\n",
    "plot_predictions(name_g511_d(detector), (), 748, data, \"XGBoostedTree\", PCA_fit=\"partfilter_g511_E8000-13000\").show()\n",
    "plot_predictions(name_g511_d(detector), (), 743, data, \"XGBoostedTree\", PCA_fit=\"partfilter_g511_E8000-50000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c84d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on other detectors\n",
    "detector = 2\n",
    "data |= {name_g511_d(detector): data_dict[name_g511_d(detector)]}\n",
    "plot_predictions(name_g511_d(detector), (), 2949, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E8000-50000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 2897, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E5000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 2851, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E5000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 739, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 748, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 743, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-50000\", xaxis_range=[-30,120]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on other detectors\n",
    "detector = 3\n",
    "data |= {name_g511_d(detector): data_dict[name_g511_d(detector)]}\n",
    "plot_predictions(name_g511_d(detector), (), 2949, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E8000-50000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 2897, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E5000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 2851, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E5000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 739, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 748, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(detector), (), 743, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-50000\", xaxis_range=[-30,120]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53faac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on part of set of detector 3\n",
    "plot_predictions(name_g511_d(3), (5000,50000), 2949, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E8000-50000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(3), (5000,50000), 2897, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E5000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(3), (5000,50000), 2851, data, \"MLPRegressorModel\", PCA_transform_on=\"partfilter_g511_E5000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(3), (5000,50000), 739, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(3), (5000,50000), 748, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-13000\", xaxis_range=[-30,120]).show()\n",
    "plot_predictions(name_g511_d(3), (5000,50000), 743, data, \"XGBoostedTree\", PCA_transform_on=\"partfilter_g511_E8000-50000\", xaxis_range=[-30,120]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca97990",
   "metadata": {},
   "source": [
    "### Visualise experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_sigma_lists = lambda dic: {k:[{d_k:pd.Series([d[str(i)][d_k][\"sigma\"] for i in range(len(d))])} for d_k in d[\"0\"].keys() if not \"data\" in d_k] for k,d in dic.items()}\n",
    "exp_results = lambda dic: {k:{\"test\" if \"test\" in d_k else \"train\": ls_d for d_k,ls_d in (ls[0]|ls[1]).items()} for k,ls in dic.items()}\n",
    "exp_res = lambda dic: {key: {k[k.find(\", \")+2: k.find(\"[\",k.find(\", \"))-2]:v for k,v in dic.items() if key in k} for key in {ky[ky.rfind(\"[\"):ky.find(\"]\")+1] for ky in dic.keys()}}\n",
    "series_ls = lambda dic: [pd.Series(s, name=n) for n,s in {k+\"_\"+i+\"_\"+j: v[i][j] for k,v in dic.items() for j in [\"test\",\"train\"] for i in v.keys()}.items()]\n",
    "# df_results = pd.DataFrame(series_ls(exp_res(exp_results(exp_sigma_lists(results)))))\n",
    "# df_results.index = pd.Index([\"[\"+i[i.rfind(\"'\")+3:i.rfind(\"]\")+1]+i[i.rfind(\"_\"):] for i in df_results.index])\n",
    "# display(df_results)\n",
    "# print(df_results.index)\n",
    "# df_results.to_csv(\"data/results/NN_TruncSVC_testing_gBOTHpartfltr_4000-11250.csv\")\n",
    "mult = 2*np.sqrt(2*np.log(2))\n",
    "# break\n",
    "df = pd.read_csv(\"data/results/XGBoost_g511unfiltered_10350-14000.csv\").set_index(\"experiment\")\n",
    "df_new = pd.DataFrame(data=[(i[1:i.find(\",\")],i[i.find(\",\")+1:i.rfind(\",\")], i[i.rfind(\",\")+1:i.find(\"]\")], \"test\" if \"test\" in i else \"train\", val*mult) for i,s in df.iterrows() for val in s.values if not pd.isna(val)],\n",
    "                      columns=[\"PCA components\",\"# estimators\",\"Max tree depth\",\"set\",\"FWHM\"])\n",
    "# df_new\n",
    "px.box(df_new, x=\"PCA components\", y=\"FWHM\", color=\"# estimators\",facet_col=\"set\",\n",
    "       hover_data=[\"set\",\"# estimators\"], points=\"all\" # add day column to hover data\n",
    "       ).update_traces(boxmean=True).update_layout(title=\"Box plots of XGBoost hyperparameter optimization (g511 & g1274 unfiltered)\").show()\n",
    "\n",
    "df = pd.read_csv(\"data/results/XGBoost2_g511unfiltered_10350-14000.csv\").set_index(\"experiment\")\n",
    "df_new = pd.DataFrame(data=[(i[1:i.find(\",\")],i[i.find(\",\")+1:i.rfind(\",\")], i[i.rfind(\",\")+1:i.find(\"]\")], \"test\" if \"test\" in i else \"train\", val*mult) for i,s in df.iterrows() for val in s.values if not pd.isna(val)],\n",
    "                      columns=[\"PCA components\",\"# estimators\",\"Max tree depth\",\"set\",\"FWHM\"])\n",
    "px.box(df_new, x=\"Max tree depth\", y=\"FWHM\", color=\"# estimators\",facet_col=\"set\", facet_row=\"PCA components\",\n",
    "       hover_data=[\"set\",\"# estimators\"], points=\"all\" # add day column to hover data\n",
    "       ).update_traces(boxmean=True).update_layout(title=\"Box plots of XGBoost hyperparameter optimization (g511unfiltered, 10350<E<14000)\", height=750).show()\n",
    "\n",
    "df = pd.read_csv(\"data/results/PCA_testing_g1274_4000-5000.csv\").set_index(\"experiment\")\n",
    "df_new = pd.DataFrame(data=[(i[:i.find(\"_\")], i[i.find(\"_\")+1:i.rfind(\"_\")], \"test\" if \"test\" in i else \"train\", val*mult) for i,s in df.iterrows() for val in s.values if not pd.isna(val)],\n",
    "                      columns=[\"Hidden layers\",\"PCA components\",\"set\",\"FWHM\"])\n",
    "px.box(df_new[df_new[\"set\"] == \"test\"], x=\"PCA components\", y=\"FWHM\", color=\"Hidden layers\", #[df_new[\"set\"] == \"test\"]\n",
    "       hover_data=[\"set\"], points=\"all\" # add day column to hover data\n",
    "       ).update_traces(boxmean=True).update_layout(title=\"Box plots of PCA analysis (g1274, 4000<E<5000)\").show()\n",
    "\n",
    "df = pd.read_csv(\"data/results/PCA_testing_g511_10350-14000.csv\").set_index(\"experiment\")\n",
    "df_new = pd.DataFrame(data=[(i[:i.find(\"_\")], i[i.find(\"_\")+1:i.rfind(\"_\")], \"test\" if \"test\" in i else \"train\", val*mult) for i,s in df.iterrows() for val in s.values if not pd.isna(val)],\n",
    "                      columns=[\"Hidden layers\",\"PCA components\",\"set\",\"FWHM\"])\n",
    "px.box(df_new[df_new[\"set\"] == \"test\"], x=\"PCA components\", y=\"FWHM\", color=\"Hidden layers\",\n",
    "       hover_data=[\"set\"], points=\"all\" # add day column to hover data\n",
    "       ).update_traces(boxmean=True).update_layout(title=\"Box plots of PCA analysis (g511, 10350<E<14000)\").show()\n",
    "\n",
    "df = pd.read_csv(\"data/results/PCA_testing_g511_11050-11250.csv\").set_index(\"experiment\")\n",
    "df_new = pd.DataFrame(data=[(i[:i.find(\"_\")], i[i.find(\"_\")+1:i.rfind(\"_\")], \"test\" if \"test\" in i else \"train\", val*mult) for i,s in df.iterrows() for val in s.values if not pd.isna(val)],\n",
    "                      columns=[\"Hidden layers\",\"PCA components\",\"set\",\"FWHM\"])\n",
    "px.box(df_new[df_new[\"set\"] == \"test\"], x=\"PCA components\", y=\"FWHM\", color=\"Hidden layers\", #[df_new[\"set\"] == \"test\"]\n",
    "       hover_data=[\"set\"], points=\"all\" # add day column to hover data\n",
    "       ).update_traces(boxmean=True).update_layout(title=\"Box plots of PCA analysis (g511, 11050<E<11250)\").show()\n",
    "\n",
    "df = pd.read_csv(\"data/results/PCA_testing_g511unfiltered_11050-11250.csv\").set_index(\"experiment\")\n",
    "df_new = pd.DataFrame(data=[(i[:i.find(\"_\")], i[i.find(\"_\")+1:i.rfind(\"_\")], \"test\" if \"test\" in i else \"train\", val*mult) for i,s in df.iterrows() for val in s.values if not pd.isna(val)],\n",
    "                      columns=[\"Hidden layers\",\"PCA components\",\"set\",\"FWHM\"])\n",
    "px.box(df_new[df_new[\"set\"] == \"test\"], x=\"PCA components\", y=\"FWHM\", color=\"Hidden layers\", #[df_new[\"set\"] == \"test\"]\n",
    "       hover_data=[\"set\"], points=\"all\" # add day column to hover data\n",
    "       ).update_traces(boxmean=True).update_layout(title=\"Box plots of PCA analysis (g511 unfiltered, 11050<E<11250)\").show()\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/results/PCA_testing_2-128_th60.csv\").set_index(\"experiment\")\n",
    "df_new = pd.DataFrame(data=[(i[:i.find(\"_\")], i[i.find(\"_\")+1:i.rfind(\"_\")], \"test\" if \"test\" in i else \"train\", val*mult) for i,s in df.iterrows() for val in s.values if not pd.isna(val)],\n",
    "                      columns=[\"Hidden layers\",\"PCA components\",\"set\",\"FWHM\"])\n",
    "px.box(df_new[df_new[\"set\"] == \"test\"], x=\"PCA components\", y=\"FWHM\", color=\"Hidden layers\",\n",
    "       hover_data=[\"set\"], points=\"all\" # add day column to hover data\n",
    "       ).update_traces(boxmean=True).update_layout(title=\"Box plots of PCA analysis (th60)\").show()\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/results/PCA_testing_gBOTH_4000-11250.csv\").set_index(\"experiment\")\n",
    "df_new = pd.DataFrame(data=[(i[:i.find(\"_\")], i[i.find(\"_\")+1:i.rfind(\"_\")], \"test\" if \"test\" in i else \"train\", val*mult) for i,s in df.iterrows() for val in s.values if not pd.isna(val)],\n",
    "                      columns=[\"Hidden layers\",\"PCA components\",\"set\",\"sigma\"])\n",
    "px.box(df_new[df_new[\"set\"] == \"test\"], x=\"PCA components\", y=\"sigma\", color=\"Hidden layers\",\n",
    "       hover_data=[\"set\"], points=\"all\" # add day column to hover data\n",
    "       ).update_traces(boxmean=True).update_layout(title=\"Box plots of PCA analysis g511 & g1274 COMBINED (test)\", yaxis_title=\"FWHM\").show()\n",
    "px.box(df_new[df_new[\"set\"] == \"train\"], x=\"PCA components\", y=\"sigma\", color=\"Hidden layers\",\n",
    "       hover_data=[\"set\"], points=\"all\" # add day column to hover data\n",
    "       ).update_traces(boxmean=True).update_layout(title=\"Box plots of PCA analysis g511 & g1274 COMBINED (train)\", yaxis_title=\"FWHM\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = mlflow.search_runs(experiment_ids=[\"610951557482905968\"],search_all_experiments=True)\n",
    "all_runs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_values = {} #{\"Energy range used\": \"() eV\"}\n",
    "\n",
    "# FROM https://jse.amstat.org/v14n3/langford.html: \"CDF Method 4 includes the middle measurement in the case of n= 4k + 1 and excludes it in the case of n= 4k + 3\"\n",
    "\n",
    "# # ??? / Sklearn NN, Na22 th.60 Ch[] / Energy included for training / 7 pts/box\n",
    "# box = box_plot([713354320025437357], x=\"Hidden layers\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"PCA components\", ignore_vals=ignore_values, height=400, width=700, title=\" \") # hover_name=\"model_version\"\n",
    "# box = box.update_layout(xaxis_range=[-.4,0.4],yaxis_range=[4,8],margin=dict(l=20, r=20, t=20, b=20))\n",
    "# box.show()  # original FWHM 32.1653\n",
    "# box.write_image(\"0_PCAHiddenLayerTesting_th60_exploration.pdf\")\n",
    "\n",
    "# # Hidden layers testing / Sklearn NN, Na22 th.06 Ch[0, 69] / Energy included for training / 7 pts/box\n",
    "# box = box_plot([955484227220031017], x=\"Hidden layers\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"PCA components\", ignore_vals=ignore_values, height=400, width=700, title=\" \")\n",
    "# box = box.update_layout(xaxis_range=[-.4,4.4],margin=dict(l=20, r=20, t=20, b=20))\n",
    "# box.show()  # original FWHM 8.0392\n",
    "# box.write_image(\"1_PCAHiddenLayerTesting_th06_layers.pdf\")\n",
    "\n",
    "# # Layer size testing / Sklearn NN, Na22 th.06 Ch[0, 420] / Energy included for training / 7 pts/box\n",
    "# box = box_plot([782813455858471214], x=\"Hidden layers\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"PCA components\", ignore_vals=ignore_values, height=400, width=700, title=\" \")\n",
    "# box = box.update_layout(xaxis_range=[-.4,5.4],margin=dict(l=20, r=20, t=20, b=20))\n",
    "# box.show()  # original FWHM 8.0392\n",
    "# box.write_image(\"2_PCAHiddenLayerTesting_th06_PandA.pdf\")\n",
    "\n",
    "# PCA testing? / Sklearn NN, Na22 th.06 Ch[0, 360] / Energy included for training / 7 pts/box\n",
    "box = box_plot([610951557482905968], x=\"Hidden layers\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"PCA components\", ignore_vals=ignore_values, facet_row=\"Alpha\", height=400, width=700, title=\" \")\n",
    "box = box.update_layout(xaxis_range=[-.4,5.4],yaxis_range=[4.7,5.9],margin=dict(l=20, r=20, t=20, b=20))\n",
    "box.show()  # original FWHM 8.0392\n",
    "box.write_image(\"3_PCAHiddenLayerTesting_th06_alpha.pdf\")\n",
    "\n",
    "# Hidden layer size == PCA analysis / Sklearn NN, Na22 th.60 Ch[0, 60] / Energy included for training / 7 pts/box #, ignore_vals={}\n",
    "ignore_values = {(\"Hidden layers\",\"PCA components\"):[[\"[16]\"],[f\"{x}\" for x in [2,4,6,8,10,12,14,18,20,21,22,23,24,28,32,36,40,44,48,56,64]]]}\n",
    "box = box_plot([568754552756492242], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), load_cols=\"Hidden layers\", ignore_vals=ignore_values, height=400, width=700, show_original_FWHM=8.0392, title=\" \")\n",
    "box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20))\n",
    "box.show()\n",
    "box.write_image(\"4_PCAHiddenLayerTesting_th60_PandAself.pdf\")\n",
    "\n",
    "# Hidden layer == 16 PCA analysis / Sklearn NN, Na22 th.60 Ch[0, 60] / Energy included for training / 7 pts/box\n",
    "ignore_values = {\"Hidden layers\":[f\"[{x}]\" for x in [2,4,6,8,10,12,14,18,20,21,22,23,24,28,32,36,40,44,48,56,64]]}\n",
    "box = box_plot([568754552756492242], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Hidden layers\", ignore_vals=ignore_values, height=400, width=700, show_original_FWHM=8.0392, showlegend=False, title=\" \")\n",
    "box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20))\n",
    "box.show()\n",
    "box.write_image(\"5_PCAHiddenLayerTesting_th60_PandA16.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(select_from_source(data[name_g511_d(2)],select_energies=(converter[2][0],70000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pca: TruncatedSVD = fitted_PCA(537, get_waveforms(source_data=data_dict[data_g511_partfltr_name_all],select_energies=(10300,12000),select_channels=0), \"XGBoostedTree\")\n",
    "fig_tree_predict0 = plot_predictions(name_g511_d(0),(converter[0][0],70000), 537, data, \"XGBoostedTree\", 0, PCA_fit=fitted_pca, mode=\"Line\", bins=[-60,70,2]) # expected: 8.276, bins=[-50,100,.5]\n",
    "fig_tree_predict1 = plot_predictions(name_g511_d(1),(converter[1][0],70000), 537, data, \"XGBoostedTree\", 1, PCA_fit=fitted_pca, mode=\"Line\", bins=[-60,70,2]) # expected: 8.276, bins=[-50,100,.5]\n",
    "fig_tree_predict2 = plot_predictions(name_g511_d(2),(converter[2][0],70000), 537, data, \"XGBoostedTree\", 2, PCA_fit=fitted_pca, mode=\"Line\", bins=[-60,70,2]) # expected: 8.276, bins=[-50,100,.5]\n",
    "fig_tree_predict0 = fig_tree_predict0.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=300, width=1100, title=\"\", xaxis_title=\"time [ns]\", yaxis_title=\"Prevalence\") #, showlegend=False\n",
    "fig_tree_predict1 = fig_tree_predict1.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=300, width=1100, title=\"\", xaxis_title=\"time [ns]\", yaxis_title=\"Prevalence\")\n",
    "fig_tree_predict2 = fig_tree_predict2.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=300, width=1100, title=\"\", xaxis_title=\"time [ns]\", yaxis_title=\"Prevalence\")\n",
    "fig_tree_predict0.show()\n",
    "fig_tree_predict1.show()\n",
    "fig_tree_predict2.show()\n",
    "fig_tree_predict0.write_image(\"12_tree_gaussians_v537_ch0.pdf\")\n",
    "fig_tree_predict1.write_image(\"13_tree_gaussians_v537_ch1.pdf\")\n",
    "fig_tree_predict2.write_image(\"14_tree_gaussians_v537_ch2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??? analysis / Sklearn NN, Na22 th.60 Ch[0, 60] / Energy included for training / 7 pts/box\n",
    "# ignore_values = {\"Hidden layers\":[f\"[{x}]\" for x in [2,4,6,8,10,12,14,18,20,21,22,23,24,28,32,36,40,44,48,56,64]]}\n",
    "# g511[0-10]: 701038535816704618, testing basic PCA & hidden layer setups\n",
    "# g511[0-20]: 913292701605665259, testing basic PCA & hidden layer setups\n",
    "# g1274[0-20]: 522945764508646794, testing basic PCA & hidden layer setups -> 23 is best\n",
    "# g511[0-13]: 855799201150735971, testing basic PCA & hidden layer setups -> 22 is best\n",
    "# 460998677625537521 - small test, 22 best\n",
    "# 167269493197702931 - reasonably larger test, 23 best\n",
    "# 915080864014606603 - unfiltered data set, ???\n",
    "# 7: 616258580092295977 - XGBTree, Na22 g511 Ch0: XGBT models, g511 unfiltered 10.35k-14k (len 22220, te/tr: 50/50)\n",
    "# 8: 737333999357308260 - XGBTree, Na22 Ch[0, 69]: XGBT models, unfiltered combined raw-5k_11.05k-11.25k, (10.35k-14k, 10.3k-12k) (len 41039, te/tr: 50/50)\n",
    "# 9: 827539381019731967 - XGBTree, Na22 Ch0: XGBT models - normalized_partfiltered_data_bothGates_4-5k_11.05k-11.25k (len 41039, te/tr: 50/50)\n",
    "#10: 102816600889877627 - XGBTree, Na22 Ch[0, 23]: XGBT models, dT correcting instead of Tfit\n",
    "#11: 941575026271596123 - SKLearnNN, Na22 Ch[0, 2, 5, 8, 9, 10]: 23,100,None PCA; [23],[16],[100]?; (5000,13000),(5000,8000),(...)\n",
    "#12: 824072748444866548 - SKLearnNN, Na22 Ch[0, 2, 5, 7, 9, 10]: 23,100,None PCA; [23],[16],[100]?; (5000,13000),(5000,8000),(...)\n",
    "\n",
    "DEFAULT_FWHM = 8.0974\n",
    "\n",
    "def square_FWHM_metric(df: pd.DataFrame) -> pd.Series:\n",
    "    ranges = {\"5000-6000\":13.3579,\"6000-7000\":11.841,\"7000-8000\":10.3735,\"8000-9000\":10.2916,\"9000-10000\":9.4387,\"10000-11000\":11.2823,\"11000-12000\":7.0638}\n",
    "    return sum([(df[f\"metrics.Uniform test FWHM E{e_range}\"]/e_val)**2 for e_range,e_val in ranges.items()]) / len(ranges) * DEFAULT_FWHM\n",
    "\n",
    "def linear_FWHM_metric(df: pd.DataFrame) -> pd.Series:\n",
    "    ranges = {\"5000-6000\":13.3579,\"6000-7000\":11.841,\"7000-8000\":10.3735,\"8000-9000\":10.2916,\"9000-10000\":9.4387,\"10000-11000\":11.2823,\"11000-12000\":7.0638}\n",
    "    return sum([df[f\"metrics.Uniform test FWHM E{e_range}\"]/e_val for e_range,e_val in ranges.items()]) / len(ranges) * DEFAULT_FWHM\n",
    "linear_FWHM_metric.FWHM = square_FWHM_metric.FWHM = DEFAULT_FWHM\n",
    "\n",
    "# metric_name = \"custom_metric_name\"\n",
    "\n",
    "# ignore_vals = {\"Number of estimators\":[\"5\",\"10\",\"20\",\"50\"]}\n",
    "# box = box_plot([616258580092295977], x=\"Number of estimators\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Max tree depth\", facet_row=\"PCA comp\", ignore_vals=ignore_vals, title=\" \") #, show_original_FWHM=8.0392\n",
    "# box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400, width=700) #, showlegend=False\n",
    "# box.show()\n",
    "# box.write_image(\"7a_TreeTesting_g511_leavesdepth.pdf\")\n",
    "\n",
    "# ignore_vals = {\"Number of estimators\":[\"1\",\"2\",\"3\"]}\n",
    "# box = box_plot([616258580092295977], x=\"Number of estimators\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Max tree depth\", facet_row=\"PCA comp\", ignore_vals=ignore_vals, title=\" \") #, show_original_FWHM=8.0392\n",
    "# box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400, width=700) #, showlegend=False\n",
    "# box.show()\n",
    "# box.write_image(\"7b_TreeTesting_g511_leavesdepth.pdf\")\n",
    "\n",
    "# box = box_plot([737333999357308260], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Number of estimators\", facet_row=\"Max tree depth\", ignore_vals={}, title=\" \") #, show_original_FWHM=8.0392\n",
    "# box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400, width=700) #, showlegend=False\n",
    "# box.show() # Unfiltered combined raw\n",
    "# box.write_image(\"8_TreeTesting_gBOTH_leavesdepth.pdf\")\n",
    "\n",
    "box = box_plot([827539381019731967], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Number of estimators\", facet_row=\"Max tree depth\", ignore_vals={}, title=\" \") #, show_original_FWHM=8.0392\n",
    "box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400, width=700) #, showlegend=False\n",
    "box.show()\n",
    "box.write_image(\"9_TreeTesting_gBOTH_leavesdepth.pdf\")\n",
    "\n",
    "#DEFAULT FWHM for below: 8.0974\n",
    "ignore_vals = {\"Energy range\":[None]}#,\"Max tree depth\":[None]}\n",
    "box = box_plot([102816600889877627], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Number of estimators\", facet_row=\"Max tree depth\", facet_col=\"Energy range\", ignore_vals=ignore_vals, title=\" \",hover_name=\"model_version\") #, show_original_FWHM=8.0392\n",
    "box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=600, width=1000) #, showlegend=False\n",
    "box.update_layout(height=600).show() # dT cprrecting instead of Tfit\n",
    "box.write_image(\"10a_TreeTesting_g511_leavesdepth.pdf\")\n",
    "\n",
    "box = box_plot([102816600889877627], x=\"PCA components\", y=square_FWHM_metric, units=(\"\",\"ns\"), color=\"Number of estimators\", facet_row=\"Max tree depth\", facet_col=\"Energy range\", ignore_vals=ignore_vals, title=\" \",hover_name=\"model_version\", custom_metric_name=\"Rel. Sq. FWHM Test\") #, show_original_FWHM=8.0392\n",
    "box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=600, width=1000) #, showlegend=False\n",
    "box.update_layout(height=600,yaxis_range=[2.9,8.3]).show()  # dT cprrecting instead of Tfit\n",
    "box.write_image(\"10b_TreeTesting_g511_leavesdepth.pdf\")\n",
    "\n",
    "print(ModelInfo.from_database(\"XGBoostedTree\", 733))\n",
    "# fitted_pca = fitted_PCA(733, get_waveforms(source_data=data_dict[data_g511_partfltr_name_all],select_energies=(8000,50000)), \"XGBoostedTree\")\n",
    "# plot_predictions(data_g511_partfltr_name_all, (4000,5000), 733, data_dict, \"XGBoostedTree\", PCA_fit=fitted_pca, bins=[-50,100,.5]).show()\n",
    "# plot_predictions(data_g511_partfltr_name_all, (6000,7000), 733, data_dict, \"XGBoostedTree\", PCA_fit=fitted_pca, bins=[-50,100,.5]).show()\n",
    "# plot_predictions(data_g511_partfltr_name_all, (10000,11000), 733, data_dict, \"XGBoostedTree\", PCA_fit=fitted_pca, bins=[-50,100,.5]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f32460",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FWHM = 16.9744\n",
    "\n",
    "def square_FWHM_metric(df: pd.DataFrame) -> pd.Series:\n",
    "    ranges = {\"5000-6000\":19.7501,\"6000-7000\":18.9533,\"7000-8000\":18.8486,\"8000-9000\":18.4477,\"9000-10000\":14.6593,\"10000-11000\":21.4188,\"11000-12000\":10.6011}\n",
    "    return sum([(df[f\"metrics.Uniform test FWHM E{e_range}\"]/e_val)**2 for e_range,e_val in ranges.items()]) / len(ranges) * DEFAULT_FWHM\n",
    "square_FWHM_metric.FWHM = DEFAULT_FWHM\n",
    "# Results [0,2,5,7,9,10] - Tfit vs T0 parameter search\n",
    "# box = box_plot([824072748444866548], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Tref\", facet_row=\"Energy range\", hover_name=\"model_version\", ignore_vals={})#, title=\" \") #, show_original_FWHM=8.0392\n",
    "# box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=800, width=1000) #, showlegend=False\n",
    "# box.show()\n",
    "# box.write_image(\"11_TreeTesting_gBOTH_leavesdepth.pdf\")\n",
    "\n",
    "# box = box_plot([824072748444866548], x=\"PCA components\", y=square_FWHM_metric, color=\"Tref\", facet_row=\"Energy range\", hover_name=\"model_version\", ignore_vals={})#, title=\" \") #, show_original_FWHM=8.0392\n",
    "# box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=800, width=1000) #, showlegend=False\n",
    "# box.show()\n",
    "# box.write_image(\"11_TreeTesting_gBOTH_leavesdepth.pdf\")\n",
    "\n",
    "# Results [0,2] for hyperparameter search, 10x repeated, from model 2v148 onwards reliable square metric\n",
    "# box = box_plot([323381473077277848], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Hidden layers\", facet_row=\"Energy range\", hover_name=\"model_version\", ignore_vals={\"Hidden layers\":\"[16]\",\"PCA components\":\"None\"})#, title=\" \") #, show_original_FWHM=8.0392\n",
    "# box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400, width=500) #, showlegend=False\n",
    "# box.show()\n",
    "# ignore_values = {(\"Hidden layers\",\"PCA components\"):[[\"[16]\"],[str(v) for v in [4,8,12,24,28,32,48,64,128]]]}\n",
    "# box = box_plot([323381473077277848], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Hidden layers\", facet_row=\"Energy range\", hover_name=\"model_version\", ignore_vals=ignore_values)#, title=\" \") #, show_original_FWHM=8.0392\n",
    "# box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400, width=500) #, showlegend=False\n",
    "# box.show()\n",
    "\n",
    "# box.write_image(\"11_TreeTesting_gBOTH_leavesdepth.pdf\")\n",
    "# SQUARE METRIC IS BROKEN FOR OLDER TESTS, DO NOT USE:\n",
    "box = box_plot([323381473077277848], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Hidden layers\", facet_row=\"Energy range\", hover_name=\"model_version\", ignore_vals={})#, title=\" \") #, show_original_FWHM=8.0392\n",
    "box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=800, width=1000) #, showlegend=False\n",
    "box.show()\n",
    "sort_by = [] #\"PCA components\"\n",
    "box = box_plot([323381473077277848], x=\"PCA components\", y=square_FWHM_metric, units=(\"\",\"ns\"), color=\"Hidden layers\", facet_row=\"Energy range\", hover_name=\"model_version\", ignore_vals={}, sort_by=sort_by)#, title=\" \") #, show_original_FWHM=8.0392\n",
    "box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=800, width=1000) #, showlegend=False\n",
    "box.show()\n",
    "# box.write_image(\"11_TreeTesting_gBOTH_leavesdepth.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29969c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by = [\"Hidden layers\",\"PCA components\"]\n",
    "box = box_plot([492805174353787986], x=\"PCA components\", y=\"FWHM Test\", units=(\"\",\"ns\"), color=\"Hidden layers\", hover_name=\"model_version\", ignore_vals={},sort_by=sort_by)#, title=\" \") #, show_original_FWHM=8.0392\n",
    "box = box.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400, width=700, title=\"\") #, showlegend=False\n",
    "box.show()\n",
    "box.write_image(\"19_FinalTestNN_good_boxes.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05745be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waveform fitting for last experiment\n",
    "data = {#data_g511_partfltr_name: datag511partfltr_all,select_channels=0,\n",
    "        \"partfilter_g511_E8000-50000\":select_from_source(datag511partfltr_all,select_channels=0,select_energies=(8000,50000)),\n",
    "        \"partfilter_g511_E5000-13000\":select_from_source(datag511partfltr_all,select_channels=0,select_energies=(5000,13000)),\n",
    "        \"partfilter_g511_all_E5000-13000\":select_from_source(datag511partfltr_all,select_channels=[0,2,5,8,9,10],select_energies=(5000,13000)),\n",
    "        \"partfilter_g511_all2_E5000-13000\":select_from_source(datag511partfltr_all,select_channels=[0,2,5,7,9,10],select_energies=(5000,13000)),\n",
    "        \"partfilter_g511_all2_E5000-50000\":select_from_source(datag511partfltr_all,select_channels=[0,2,5,7,9,10],select_energies=(5000,50000))} | {\n",
    "        name_g511_d(detector): data_dict[name_g511_d(detector)] for detector in [0,1,2,3,4,5,6,7,8,9,10,11]} | {\n",
    "        name2_g511_d(detector): data_dict[name2_g511_d(detector)] for detector in [0,1,2,3,4,5,6,7,8,9,10,11]}\n",
    "waveforms5000_13000 = get_waveforms(source_data=data[\"partfilter_g511_E5000-13000\"])\n",
    "waveforms8000_50000 = get_waveforms(source_data=data[\"partfilter_g511_E8000-50000\"])\n",
    "# waveforms5000_50000 = get_waveforms(source_data=data[\"partfilter_g511_all2_E5000-50000\"])\n",
    "fitted_pca = {model_v: fitted_PCA(model_v, fitforms, \"MLPRegressorModel\") for model_v,fitforms in {2949:waveforms8000_50000, 2897:waveforms5000_13000}.items()}\n",
    "\n",
    "source_dat = select_from_source(datag511partfltr_all,select_channels=[0,2])\n",
    "waveforms_v2 = get_waveforms(source_data=source_dat.loc[source_dat[\"s199\"] >= .95], select_energies=(5000,50000))\n",
    "source_dat_large = select_from_source(datag511partfltr_all2,select_channels=[0,1,3,5,7,9,10])\n",
    "waveforms_v2_large = get_waveforms(source_data=source_dat_large.loc[source_dat_large[\"s199\"] >= .95], select_energies=(5000,50000))\n",
    "fitted_pca |= {model_v: fitted_PCA(model_v, waveforms_v2, \"MLPRegressorModel2\") for model_v in [191,198,179,166]}\n",
    "fitted_pca |= {model_v: fitted_PCA(model_v, waveforms_v2_large, \"MLPRegressorModel2\") for model_v in [209,210,213,219]}\n",
    "fitted_pca |= {model_v: None for model_v in [230,231]}\n",
    "\n",
    "model_name = lambda integer: \"MLPRegressorModel2\" if integer < 1500 else \"MLPRegressorModel\"\n",
    "print(model_name(213), model_name(2949))\n",
    "# model_name = {166: \"MLPRegressorModel2\", 179: \"MLPRegressorModel2\", 191: \"MLPRegressorModel2\", 198: \"MLPRegressorModel2\", 2897: \"MLPRegressorModel\", 2949: \"MLPRegressorModel\"}\n",
    "# Eleastsquares 2949:  8000-50000 100-[23]  @ 5.599, 2897:  5000-13000 ALL-[100] @ 5.608, 2851:  5000-13000 100-[16] @ 5.605\n",
    "#                739:  8000-13000 16-4*40   @ 3.444,  748:  8000-13000 16-4*50   @ 3.475,  743:  8000-50000 16-4*50  @ 3.512\n",
    "# Elinear       2897:  5000-13000 ALL-[100] @ 5.651, 2949:  8000-50000 100-[23]  @ 5.654, 2851:  5000-13000 100-[16] @ 5.662\n",
    "#                748:  8000-13000 16-4*50   @ 4.367,  743:  8000-50000 16-4*50   @ 4.410,  739:  8000-13000 16-4*40  @ 4.447\n",
    "# Try 2995 also (everything from 2997 and up is BAD: dt correcting), try 2935 (FWHM 7.02) but 2949 (FWHM 6.96)\n",
    "\n",
    "e_corrections = {0: calc_ab(4477,11197),\n",
    "                 1: calc_ab(4623,11538),\n",
    "                 2: calc_ab(4212,10512),\n",
    "                 3: calc_ab(4672,11662),\n",
    "                 4: (1,0),  # LaBr channel\n",
    "                 5: calc_ab(1582,3948),\n",
    "                 6: (1,0),  # LaBr channel\n",
    "                 7: calc_ab(4747,11866),\n",
    "                 8: calc_ab(4303,10727),\n",
    "                 9: calc_ab(4750,11861),\n",
    "                 10:calc_ab(4113,10268),\n",
    "                 11: calc_ab(4474,11157)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da6e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_tup = calc_ab(4477,11197)\n",
    "print(corr_tup[0] * 5000 + corr_tup[1],corr_tup[0] * 50000 + corr_tup[1])\n",
    "corr_tup = calc_ab(4212,10512)\n",
    "print(corr_tup[0] * 5000 + corr_tup[1],corr_tup[0] * 50000 + corr_tup[1])\n",
    "corr_tup = calc_ab(1582,3948)\n",
    "print(corr_tup[0] * 5000 + corr_tup[1],corr_tup[0] * 50000 + corr_tup[1])\n",
    "print(corr_tup[0] * 1582 + corr_tup[1],corr_tup[0] * 3948 + corr_tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99834864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for last experiment\n",
    "# break\n",
    "# for channel,model_v,which in [(0,198)]:  # Fitting takes about 1.5 min, plotting is nearly instant\n",
    "#     kwargs = {\"PCA_fit\":fitted_pca[model_v],\"which\":\"Tfit\",\"bins\":[-40,80,1],\"xaxis_title\":\"time [ns]\",\"mode\":\"Line\",\"shift\":0,\"show_dt\":False,\n",
    "#               \"title\":f\"Predictions of NN2 v{model_v} on Ch{channel}, @E 2500 (arb. units, binwidth 250)\"}\n",
    "#     plot_predictions(name_g511_d(channel),(2375,2625),model_v,data,\"MLPRegressorModel2\",channel,**kwargs).show()\n",
    "#     plot_predictions(name_g511_d(channel),(4875,5125),model_v,data,\"MLPRegressorModel2\",channel,**kwargs).show()\n",
    "#     plot_predictions(name_g511_d(channel),(8875,9125),model_v,data,\"MLPRegressorModel2\",channel,**kwargs).show()\n",
    "# Try: 210, 213, 230, 231\n",
    "# energy_line_plot(name2_g511_d(2), 100, 1300, 50, 230, data, \"MLPRegressorModel2\", PCA_fit=None, correct_energy=e_corrections[2],hist_limit=700,verbose=0,y_sd=None,line_shape=\"hvh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68955e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_histogram(name_g511_d(7), data, bins=[0,14_000,10])\n",
    "plotting.settings(show_dt=False,show_pred=False,default_plot_mode=\"Line\")\n",
    "trace_names = [\"191 TCh(0,2)\", \"198 TCh(0,2)\", \"210 TCh(0-11)\", \"213 TCh(0-11)\", \"230 TCh(0-11)\", \"231 TCh(0-11)\", \"2897 TCh(0)\", \"2949 TCh(0)\"]\n",
    "trace_names = [\"209 TCh(0-11)\"]\n",
    "channel_dict = {}\n",
    "for ch in [0,1,2,3,4,5,7,8,9,10,11]: # 0,1,2,3,4,5,7,8,9,10,11\n",
    "    fig_elines = []\n",
    "    for model_v in [219]: #191, 198, 2897, 2949\n",
    "        fig_eline = energy_line_plot(name2_g511_d(ch), 100, 1300, 50, model_v, data, model_name(model_v), PCA_fit=fitted_pca[model_v], correct_energy=e_corrections[ch],hist_limit=700,verbose=0,y_sd=None,line_shape=\"hvh\")\n",
    "        fig_elines.append(fig_eline)\n",
    "    fig_ehist = energy_histogram(name2_g511_d(ch), data, select_energies=(0,1300), bins=[0,1400,2], correct_energy=e_corrections[ch], xaxis_title=\"Energy [keV]\",\n",
    "                                 title=f\"Predictions of NNs on channel {ch} (trained on channel TCh)\", colors=[\"rgba(0,0,0,0.5)\"])\n",
    "    combined_eline = combine_line_plots(fig_elines[0], fig_elines[1:], trace_names=trace_names, equality_tolerance=2e-3)\n",
    "    channel_dict[ch] = add_energy_histogram(combined_eline, fig_ehist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_dict[2].show()\n",
    "# channel_dict[4].show()\n",
    "channel_dict[8].show()\n",
    "channel_dict[11].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803c9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.settings(show_dt=False,show_pred=False,default_plot_mode=\"Line\")\n",
    "channels = [0,1,2,3,5,7,8,9,10,11] # Trained on 0, 1, 3, 5, 7, 9, 10, test on 2, 8, 11\n",
    "on_data = {ch:name2_g511_d(ch) for ch in channels}\n",
    "test_models = [191, 198, 209, 210, 213, 219, 230, 231, 2949]\n",
    "model_names = {m:model_name(m) for m in test_models}\n",
    "trace_names = [\"191\", \"198\", \"209\", \"210\", \"213\", \"219\", \"230\", \"231\", \"2949\"]\n",
    "\n",
    "fig_combined_all = combined_channel_line_plot(on_data, test_models, model_names, channels, fitted_pca, data, e_corrections, trace_names, equality_tolerance=1e-2, line_shape=\"hvh\")\n",
    "fig_combined_test = combined_channel_line_plot(on_data, test_models, model_names, [2,8,11], fitted_pca, data, e_corrections, trace_names, equality_tolerance=1e-2, line_shape=\"hvh\")\n",
    "fig_combined_all = fig_combined_all.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400,width=1000, title=\"\") #, showlegend=False #height=400, width=700\n",
    "fig_combined_test = fig_combined_test.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400,width=1000, title=\"\") #, showlegend=False #height=400, width=700\n",
    "\n",
    "change_combined_line_fig(fig_combined_all, remove_traces=[1,2,4,8,9], hide_traces=[3,5,6,7]).show()\n",
    "change_combined_line_fig(fig_combined_test, remove_traces=[1,2,4,8,9], hide_traces=[3,5,6,7]).show()\n",
    "fig_combined_all.write_image(\"20_FinalTestNN_hist_all.pdf\")\n",
    "fig_combined_test.write_image(\"21_FinalTestNN_hist_test.pdf\")\n",
    "# fig_combined_all._dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_range = lambda s,e,ch : (s*e_corrections[ch][0]+e_corrections[ch][1],e*e_corrections[ch][0]+e_corrections[ch][1])\n",
    "print(e_corrections[0], convert_range(4160,4601,0))\n",
    "print(e_corrections[1], convert_range(4297,4750,1))\n",
    "print(e_corrections[2], convert_range(3915,4328,2))\n",
    "print(e_corrections[5], convert_range(1470.4,1625.5,5))\n",
    "print(e_corrections[7], convert_range(4411,4878,7))\n",
    "print(e_corrections[8], convert_range(4000,4421,8))\n",
    "print(e_corrections[11], convert_range(4159,4597,11))\n",
    "print(e_corrections[0], convert_range(8343,9224,0))\n",
    "print(e_corrections[1], convert_range(8602,9508,1))\n",
    "print(e_corrections[2], convert_range(7837,8663,2))\n",
    "print(e_corrections[5], convert_range(2943.5,3253.3,5))\n",
    "print(e_corrections[7], convert_range(8843,9776,7))\n",
    "print(e_corrections[8], convert_range(7999,8841,8))\n",
    "print(e_corrections[11], convert_range(8320,9195,11))\n",
    "# print(convert_range(9195,70000,0))\n",
    "\n",
    "converter = {0:(4160,4601), 1:(4297,4750), 2:(3915,4328), 5:(1470.4,1625.5), 7:(4411,4878), 8:(4000,4421),11:(4159,4597)}\n",
    "converter2 = {0:(8343,9224), 1:(8602,9508), 2:(7837,8663), 5:(2943.5,3253.3), 7:(8843,9776), 8:(7999,8841),11:(8320,9195)}\n",
    "# e_corrections = {0: calc_ab(4477,11197),\n",
    "#                  1: calc_ab(4623,11538),\n",
    "#                  2: calc_ab(4212,10512),\n",
    "#                  3: calc_ab(4672,11662),\n",
    "#                  4: (1,0),  # LaBr channel\n",
    "#                  5: calc_ab(1582,3948),\n",
    "#                  6: (1,0),  # LaBr channel\n",
    "#                  7: calc_ab(4747,11866),\n",
    "#                  8: calc_ab(4303,10727),\n",
    "#                  9: calc_ab(4750,11861),\n",
    "#                  10:calc_ab(4113,10268),\n",
    "#                  11: calc_ab(4474,11157)}\n",
    "plotting.settings(show_dt=False,show_pred=False,default_plot_mode=\"Line\")\n",
    "\n",
    "for i,ch in enumerate([0,1,2,5,7,11]):\n",
    "    bs = -30\n",
    "    if ch == 11:\n",
    "        bs = -70\n",
    "    print(\"Plots for channel\",ch,\":\")\n",
    "    fig_475_525 = plot_predictions(name_g511_d(ch),converter[ch],231,data,\"MLPRegressorModel2\",ch, PCA_fit=fitted_pca[231],bins=[bs,35,1],xaxis_title=\"time [ns]\",yaxis_title=\"Prevalence\")\n",
    "    fig_475_525.show()\n",
    "    fig_475_525 = fig_475_525.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400,width=1000, title=\"\")\n",
    "    fig_950_1050 = plot_predictions(name_g511_d(ch),converter2[ch],231,data,\"MLPRegressorModel2\",ch, PCA_fit=fitted_pca[231],bins=[bs,35,1],xaxis_title=\"time [ns]\",yaxis_title=\"Prevalence\")\n",
    "    fig_950_1050.show()\n",
    "    fig_950_1050 = fig_475_525.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400,width=1000, title=\"\")\n",
    "    fig_1050_70k = plot_predictions(name_g511_d(ch),(converter2[ch][0],70000),231,data,\"MLPRegressorModel2\",ch, PCA_fit=fitted_pca[231],bins=[bs,40,1],xaxis_title=\"time [ns]\",yaxis_title=\"Prevalence\")\n",
    "    fig_1050_70k.show()\n",
    "    fig_1050_70k = fig_1050_70k.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400,width=1000, title=\"\")\n",
    "    fig_475_70k = plot_predictions(name_g511_d(ch),(converter[ch][0],70000),231,data,\"MLPRegressorModel2\",ch, PCA_fit=fitted_pca[231],bins=[bs,40,1],xaxis_title=\"time [ns]\",yaxis_title=\"Prevalence\")\n",
    "    fig_475_70k.show()\n",
    "    fig_475_70k = fig_475_70k.update_layout(margin=dict(l=20, r=20, t=20, b=20), height=400,width=1000, title=\"\")\n",
    "    # fig_475_525.write_image(f\"{i*4+24}_FinalTestNN_hist_475_525_ch{ch}.pdf\")\n",
    "    # fig_950_1050.write_image(f\"{i*4+25}_FinalTestNN_hist_950_1050_ch{ch}.pdf\")\n",
    "    # fig_1050_70k.write_image(f\"{i*4+26}_FinalTestNN_hist_1050_70k_ch{ch}.pdf\")\n",
    "    # fig_475_70k.write_image(f\"{i*4+27}_FinalTestNN_hist_475_70k_ch{ch}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2427a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = pd.DataFrame({\"Left T$_{fit}$ tail estimate\":[\"13 ns (-18 --- -5 ns)\",\"-\",\"-\",\"10 ns (-18 --- -8 ns)\",\"12 ns (-19 --- -7 ns)\"],\n",
    "                            \"Left T$_{pred}$ - T$_{fit}$ tail estimate\":[\"11 ns (-25 --- -14 ns)\",\"-\",\"-\",\"15 ns (-6 --- 9 ns)\",\"14 ns (-64 --- -50 ns)\"],\n",
    "                            \"Relative factor left tail\": [\"0.85\",\"-\",\"-\",\"1.5\",\"1.2\"],\n",
    "                            \"Right T$_{fit}$ tail estimate\":[\"30 ns (6 --- 36 ns)\",\"32 ns (6 --- 38 ns)\",\"26 ns (10 --- 36 ns)\",\"44 ns (6 --- 50 ns)\",\"38 ns (7 --- 45 ns)\"],\n",
    "                            \"Right T$_{pred}$ - T$_{fit}$ tail estimate\":[\"19 ns (-4 --- 15 ns)\",\"19 ns (-2 --- 21 ns)\",\"16 ns (-11 --- 5 ns)\",\"20 ns (21 --- 41 ns)\",\"22 ns (-39 --- -17 ns)\"],\n",
    "                            \"Relative factor right tail\": [\"0.63\",\"0.72\",\"0.62\",\"0.45\",\"0.58\"],},\n",
    "                            index = [\"Channel 1\",\"Channel 2\",\"Channel 5\",\"Channel 7\",\"Channel 11\"])\n",
    "display(latex_table)\n",
    "latex_table.to_latex(\"NN_231_tails_table.tex\")\n",
    "#Tail from Gaussian edge to Channel 1: -4 to 15 vs 6 to 36 ns -> = 0.63\n",
    "#                           Channel 2: -2 to 21 vs 6 to 38 -\\> 23/32 = 0.72. \n",
    "#                           Channel 5: -11 to 5 vs 10 to 36 -\\> 16/26 = 0.62.\n",
    "#                           Channel 7: 21 to 41 vs 6 to 50 -\\> 20/44 = 0.45, -6 to 9 vs -18 to -8 -\\> 15/10 = 1.5.\n",
    "#                           Channel 11: -39 to -17 vs 7 to 45 -\\> 22/38 = 0.58, -64 to -50 vs -19 to -7 -\\> 14/12 = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [0,1,2]\n",
    "test_models = [191, 2949]\n",
    "trace_names = [\"191 TCh(0,2)\", \"2949 TCh(0)\"]\n",
    "model_names = {m:model_name(m) for m in test_models}\n",
    "on_data = {ch:name2_g511_d(ch) for ch in channels}\n",
    "\n",
    "combined_channel_line_plot(on_data, test_models, model_names, channels, fitted_pca, data, e_corrections, trace_names, line_shape=\"hvh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc939bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.settings(show_dt=False,show_pred=False,default_plot_mode=\"Line\")\n",
    "channels = [0,1,2,3,5,7,8,9,10,11] # Trained on 0, 1, 3, 5, 7, 9, 10, test on 2, 8, 11\n",
    "on_data = {ch:name2_g511_d(ch) for ch in channels}\n",
    "test_models = [191, 198, 209, 210, 213, 230, 231, 2897, 2949]\n",
    "test_models = [191, 198, 209, 210, 213, 219, 230, 231, 2949]\n",
    "model_names = {m:model_name(m) for m in test_models}\n",
    "trace_names = [\"191 TCh(0,2)\", \"198 TCh(0,2)\", \"209 TCh(0-11)\", \"210 TCh(0-11)\", \"213 TCh(0-11)\", \"230 TCh(0-11)\", \"231 TCh(0-11)\", \"2897 TCh(0)\", \"2949 TCh(0)\"]\n",
    "trace_names = [\"191\", \"198\", \"209\", \"210\", \"213\", \"219\", \"230\", \"231\", \"2949\"]\n",
    "\n",
    "df_table_all = combined_channel_line_plot(on_data, test_models, model_names, channels, fitted_pca, data, e_corrections, trace_names, to_table=1, equality_tolerance=2e-3)\n",
    "df_table_test = combined_channel_line_plot(on_data, test_models, model_names, [2,8,11], fitted_pca, data, e_corrections, trace_names, to_table=1, equality_tolerance=2e-3)\n",
    "\n",
    "s_percentage = lambda df, tracename: df[f\"[{tracename}] Tpred - Tref\"] / df[\"Tfit\"]\n",
    "s_percentage_sd = lambda df, tracename: s_percentage(df,tracename) * np.sqrt(\n",
    "    (df[f\"[{tracename}] Tpred - Tref SD\"] / df[f\"[{tracename}] Tpred - Tref\"])**2 + (df[f\"Tfit SD\"] / df[f\"Tfit\"])**2\n",
    ")\n",
    "s_gain = lambda df, tracename: df[\"Tfit\"] - df[f\"[{tracename}] Tpred - Tref\"]\n",
    "s_gain_sd = lambda df, tracename: np.sqrt(df[\"Tfit SD\"]*df[\"Tfit SD\"] + df[f\"[{tracename}] Tpred - Tref\"]*df[f\"[{tracename}] Tpred - Tref\"])\n",
    "get_df_gain = lambda df, tracename: pd.DataFrame({\n",
    "                                                    tracename:df[f\"[{tracename}] Tpred - Tref\"],\n",
    "                                                    tracename+\" SD\":df[f\"[{tracename}] Tpred - Tref SD\"],\n",
    "                                                    tracename+\" Rel.Gain\":s_percentage(df, tracename),\n",
    "                                                    tracename+\" Rel.Gain SD\":s_percentage_sd(df, tracename),\n",
    "                                                    # tracename+\" AbsGain\":s_gain(df, tracename),\n",
    "                                                    # tracename+\" AbsGain SD\":s_gain_sd(df, tracename)\n",
    "                                                 })\n",
    "get_df_gain_combined = lambda df, *tracenames: pd.concat([df[[\"Tfit\",\"Tfit SD\"]]]+[get_df_gain(df, tracename) for tracename in tracenames],axis=1)\n",
    "get_df_means = lambda dfs, *tracenames: pd.DataFrame({k: get_df_gain_combined(v,*tracenames).mean() for k,v in dfs.items()}).T\n",
    "\n",
    "df_table_all_sd = get_df_gain_combined(df_table_all,\"209\", \"213\", \"219\", \"230\", \"231\") #\"191 TCh(0,2)\", \"198 TCh(0,2)\"\n",
    "df_table_test_sd = get_df_gain_combined(df_table_test, \"209\", \"213\", \"219\", \"230\", \"231\")\n",
    "\n",
    "display(df_table_test_sd)\n",
    "df_means = get_df_means({\"All channel data (0-11, excl. 4,6)\":df_table_all,\"Test channel data (2,8,11)\":df_table_test},\"209\", \"213\", \"219\", \"230\", \"231\")\n",
    "df_table_means = combine_cols_with_errors(df_means, round=3).T\n",
    "display(df_table_means)\n",
    "df_table_means.to_latex(\"NNmeans_table.tex\")\n",
    "df_table_test_sd_rel = combine_cols_with_errors(df_table_test_sd[[col for col in df_table_test_sd.columns if (\"Rel\" in col or \"Tfit\" in col)]], round=3)\n",
    "df_table_test_sd_abs = combine_cols_with_errors(df_table_test_sd[[col for col in df_table_test_sd.columns if \"Rel\" not in col]], round=3)\n",
    "df_table_test_sd_rel.index = df_table_test_sd_rel.index.astype(int)\n",
    "df_table_test_sd_abs.index = df_table_test_sd_abs.index.astype(int)\n",
    "display(df_table_test_sd_rel)\n",
    "display(df_table_test_sd_abs)\n",
    "df_table_test_sd_rel.to_latex(\"NN_FWHM_table_test_relative.tex\")\n",
    "df_table_test_sd_abs.to_latex(\"NN_FWHM_table_test_absolute.tex\")\n",
    "df_table_all_sd_rel = combine_cols_with_errors(df_table_all_sd[[col for col in df_table_all_sd.columns if (\"Rel\" in col or \"Tfit\" in col)]], round=3)\n",
    "df_table_all_sd_abs = combine_cols_with_errors(df_table_all_sd[[col for col in df_table_all_sd.columns if \"Rel\" not in col]], round=3)\n",
    "df_table_all_sd_rel.index = df_table_all_sd_rel.index.astype(int)\n",
    "df_table_all_sd_abs.index = df_table_all_sd_abs.index.astype(int)\n",
    "display(df_table_all_sd_rel)\n",
    "display(df_table_all_sd_abs)\n",
    "df_table_all_sd_rel.to_latex(\"NN_FWHM_table_all_relative.tex\")\n",
    "df_table_all_sd_abs.to_latex(\"NN_FWHM_table_all_absolute.tex\")\n",
    "# df_table.to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb4d2c-3fa3-42f4-8ceb-85840e1058df",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
